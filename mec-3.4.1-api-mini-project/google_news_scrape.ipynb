{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "# scrape stock data from google news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import random \n",
    "from collections import OrderedDict\n",
    "\n",
    "# List of header that contain User-Agent\n",
    "def list_header():\n",
    "    headers_list = [\n",
    "        # Firefox 24 Linux\n",
    "        {\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:24.0) Gecko/20100101 Firefox/24.0',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        },\n",
    "        # Firefox Mac\n",
    "        {\n",
    "            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "            'Accept-Language': 'en-US,en;q=0.5',\n",
    "            'DNT': '1',\n",
    "            'Connection': 'keep-alive',\n",
    "            'Upgrade-Insecure-Requests': '1',\n",
    "        }\n",
    "    ]\n",
    "    return headers_list\n",
    "\n",
    "def list_dict():\n",
    "    # Get headers list\n",
    "    headers_list = list_header()\n",
    "    # Create ordered dict from Headers above\n",
    "    ordered_headers_list = []\n",
    "    for headers in headers_list:\n",
    "        h = OrderedDict()\n",
    "        for header,value in headers.items():\n",
    "            h[header]=value\n",
    "        ordered_headers_list.append(h)\n",
    "    return ordered_headers_list\n",
    "\n",
    "def list_test():\n",
    "    headers_list = list_dict()\n",
    "    max = len(headers_list)\n",
    "    url = 'https://httpbin.org/headers'\n",
    "    for i in range(0,max):\n",
    "        #Pick a random browser headers\n",
    "        headers = random.choice(headers_list)\n",
    "        #Create a request session\n",
    "        r = requests.Session()\n",
    "        r.headers = headers\n",
    "        \n",
    "        response = r.get(url)\n",
    "        print(\"Request #%d\\nUser-Agent Sent:%s\\n\\nHeaders Recevied by HTTPBin:\"%(i,headers['User-Agent']))\n",
    "        print(response.json())\n",
    "        print(\"-------------------\")\n",
    "\n",
    "def random_header():\n",
    "    headers_list = list_dict()\n",
    "    headers = random.choice(headers_list)\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "source_hidden": false
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google news URL to scrape = https://www.cnbc.com/2021/07/21/a-key-stat-hidden-in-verizons-report-could-spell-good-news-for-apple.html\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/19/why-apple-stock-was-falling-monday/\n",
      "Google news URL to scrape = https://www.fxstreet.com/news/apple-aapl-stock-forecast-why-is-apple-falling-will-results-boost-stock-the-stock-price-202107191034\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/20/what-disney-and-apple-investors-should-look-for-du/\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/21/why-netflix-stock-fell-nearly-5-on-wednesday/\n",
      "Google news URL to scrape = https://www.fxstreet.com/news/netflix-nflx-stock-price-and-forecast-earnings-are-mixed-but-let-the-games-begin-202107211026\n",
      "Google news URL to scrape = https://www.investors.com/news/technology/netflix-stock-netflix-edges-subscriber-target-but-earnings-miss/\n",
      "Google news URL to scrape = https://www.forbes.com/sites/greatspeculations/2021/07/16/whats-next-for-netflix-stock-after-its-11-rally/\n",
      "Google news URL to scrape = https://pulse2.com/zm-stock-380-target-from-citi/\n",
      "Google news URL to scrape = https://www.profitconfidential.com/news/zoom-video-communications-inc-zm-stock/\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/zoom-video-communications-zm-stock-214509116.html\n",
      "Google news URL to scrape = https://www.investors.com/news/technology/zoom-stock-falls-five9-stock-acquisition-zm-stock/\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/zoom-video-communications-zm-stock-214509947.html\n",
      "Google news URL to scrape = https://www.marketbeat.com/instant-alerts/nasdaq-adbe-insider-buying-and-selling-2021-07-2-3/\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/01/3-reasons-why-adobe-stock-is-dirt-cheap-right-now/\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/adobe-inc-adbe-great-investment-163853048.html\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/22/3-top-tech-stocks-to-buy-during-a-recession/\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/06/23/reasons-buy-adobe-stock-after-strong-q2-earnings/\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/did-participate-microsofts-nasdaq-msft-083738605.html\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/10-best-stocks-buy-according-180618557.html\n",
      "Google news URL to scrape = https://www.barrons.com/articles/microsoft-stock-hits-new-high-as-street-raises-price-targets-ahead-of-earnings-51626965343\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/microsoft-msft-earnings-expected-grow-190207796.html\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/microsoft-msft-stock-moves-1-214509891.html\n",
      "Google news URL to scrape = https://finance.yahoo.com/news/tesla-tsla-stock-sinks-market-214509509.html\n",
      "Google news URL to scrape = https://www.fool.com/investing/2021/07/20/why-tesla-stock-popped-again-tuesday/\n",
      "Google news URL to scrape = https://www.coinspeaker.com/tsla-musk-tesla-supercharger/\n",
      "Google news URL to scrape = https://www.fxstreet.com/news/tesla-tsla-stock-price-and-forecast-why-is-tesla-stock-moving-202107221014\n",
      "Google news URL to scrape = https://electrek.co/2021/07/20/tesla-tsla-could-make-more-money-from-software-subscription-than-hardware/\n"
     ]
    }
   ],
   "source": [
    "# INGESTION THROUGH WEB SCRAPING USING BEAUTIFULSOUP\n",
    "import requests\n",
    "import pandas as pd\n",
    "import bs4\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "def ingest_google_news():\n",
    "    ticker_list = ['AAPL', 'GOOG', 'FB','NFLX', 'NVDA', 'ZM', 'ADBE', 'MSFT', 'TSLA']\n",
    "\n",
    "    sep = '.'\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    t_news = []\n",
    "    t_publisher = []\n",
    "    t_urls = []\n",
    "    t_dates = []\n",
    "    t_tickers = []\n",
    "\n",
    "    for t in ticker_list:\n",
    "        news = []\n",
    "        publisher = []\n",
    "        urls = []\n",
    "        dates = []\n",
    "        tickers = []\n",
    "\n",
    "        # cleaning ticker\n",
    "        ticker = t\n",
    "        t = t.split(sep, 1)[0]\n",
    "\n",
    "        # set header by random user agent \n",
    "        r = requests.Session()\n",
    "        headers = random_header()\n",
    "        r.headers = headers\n",
    "        # print(headers)\n",
    "\n",
    "        # set query for google\n",
    "        query = '{} stock news'.format(t)\n",
    "        url = f\"https://www.google.com/search?q={query}&tbm=nws&lr=lang_en&hl=en&sort=date&num=5\"\n",
    "        res = r.get(url, headers=headers)\n",
    "        soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
    "        \n",
    "        links = soup.select(\".dbsr a\")\n",
    "        for l in links:\n",
    "            tickers.append(t)\n",
    "            try:\n",
    "                url_w = l.get(\"href\")\n",
    "                print(\"Google news URL to scrape = \" + url_w)\n",
    "                urls.append(url_w)\n",
    "                dt = find_date(url_w)\n",
    "                dates.append(dt)\n",
    "\n",
    "                res = requests.get(url_w, headers=headers)\n",
    "                parsed_article = bs4.BeautifulSoup(res.text,'lxml')\n",
    "                paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "                article_text = \"\"\n",
    "                for p in paragraphs:\n",
    "                    article_text += p.text\n",
    "\n",
    "            except Exception as e:\n",
    "                article_text = ''\n",
    "\n",
    "            news.append(article_text)\n",
    "\n",
    "        sources = soup.select(\".XTjFC g-img\")\n",
    "        for s in sources:\n",
    "            publisher.append(s.next_sibling.lower())\n",
    "\n",
    "        t_urls += urls\n",
    "        t_news += news\n",
    "        t_publisher += publisher\n",
    "        t_dates += dates\n",
    "        t_tickers += tickers\n",
    "\n",
    "    df['ticker'] = t_tickers\n",
    "    df['links'] = t_urls\n",
    "    df['article_text'] = t_news\n",
    "    df['publisher'] = t_publisher\n",
    " #   df['created_at'] = t_dates\n",
    "\n",
    "    # import to csv\n",
    "    today = date.today()\n",
    "    d1 = today.strftime(\"%d%m%Y\")\n",
    "    df.to_csv(f'./datasets/google_news_{d1}.csv')\n",
    "\n",
    "    del news, publisher, urls, dates, tickers\n",
    "    del t_news, t_publisher, t_urls, t_dates, ticker\n",
    "\n",
    "\n",
    "ingest_google_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucsd-1",
   "language": "python",
   "name": "ucsd-1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
