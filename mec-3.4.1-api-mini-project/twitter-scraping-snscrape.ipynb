{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import re\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from ipywidgets import interact, widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data based on input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#NIFTY\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "query = widgets.Text(\n",
    " placeholder=â€™Enter your stock tockerâ€™,\n",
    " description=â€™stock:â€™\n",
    " )\n",
    "display(txtsl)\n",
    "'''\n",
    "\n",
    "query = \"#NIFTY\"\n",
    "print(query)\n",
    "\n",
    "# Create a data folder in your current dir.\n",
    "def SaveData(df, filename):\n",
    "    df.to_csv(\"./datasets/\" + filename + \".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying for = #NIFTY\n",
      "                     Datetime             Tweet Id  \\\n",
      "0   2021-07-21 21:45:38+00:00  1417964006514388993   \n",
      "1   2021-07-21 21:42:59+00:00  1417963340941336578   \n",
      "2   2021-07-21 20:23:41+00:00  1417943384170262530   \n",
      "3   2021-07-21 20:21:59+00:00  1417942954908569604   \n",
      "4   2021-07-21 19:06:13+00:00  1417923890798419968   \n",
      "..                        ...                  ...   \n",
      "96  2021-07-21 07:41:48+00:00  1417751649737592834   \n",
      "97  2021-07-21 07:38:34+00:00  1417750837300920323   \n",
      "98  2021-07-21 07:38:15+00:00  1417750758292791298   \n",
      "99  2021-07-21 07:37:08+00:00  1417750475630276608   \n",
      "100 2021-07-21 07:36:24+00:00  1417750292142059523   \n",
      "\n",
      "                                                  Text         Username  \n",
      "0    Short covering pe short covering \\n15900 \\n#nifty        NiftySher  \n",
      "1    All indicators point to a 100 pts gap UP for #...         MiliSony  \n",
      "2    Strong recovery in US markets.\\n\\nSGX nifty su...  MarketsNonSense  \n",
      "3    wanted to invest in good stocks\\n\\nI said #Uni...     SandeepRokde  \n",
      "4    Not interested in #ZomatoIPO but do consider #...       Investodog  \n",
      "..                                                 ...              ...  \n",
      "96   Shyam Metallics Q1 result update\\n\\nRevenue 1,...   BigBreakingNow  \n",
      "97   Mangalam Cement Q1 result update\\n\\nRevenue 35...   BigBreakingNow  \n",
      "98   Astron Paper Q1 result update \\n\\nRevenue 112 ...   BigBreakingNow  \n",
      "99   If trading is Love then Investing is Wife ðŸŽŠðŸš€ðŸš€ðŸš€...         YasHisHh  \n",
      "100  Bajaj Finserv Q1 results: PAT falls 31% YoY to...   wakeupwhistleC  \n",
      "\n",
      "[101 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Get user input\n",
    "#query = input(\"Query: \")\n",
    "query = \"#NIFTY\"\n",
    "print(\"Querying for = \" + query)\n",
    "\n",
    "#As long as the query is valid (not empty or equal to '#')...\n",
    "if query != '':\n",
    "    noOfTweet = 100. #input(\"Enter the number of tweets you want to Analyze: \")\n",
    "    if noOfTweet != '' :\n",
    "        noOfDays = 2 # input(\"Enter the number of days you want to Scrape Twitter for: \")\n",
    "        if noOfDays != '':\n",
    "                #Creating list to append tweet data\n",
    "                tweets_list = []\n",
    "                now = dt.date.today()\n",
    "                now = now.strftime('%Y-%m-%d')\n",
    "                yesterday = dt.date.today() - dt.timedelta(days = int(noOfDays))\n",
    "                yesterday = yesterday.strftime('%Y-%m-%d')\n",
    "                for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query + ' lang:en since:' +  yesterday + ' until:' + now + ' -filter:links -filter:replies').get_items()):\n",
    "                    if i > int(noOfTweet):\n",
    "                        break\n",
    "                    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "\n",
    "                #Creating a dataframe from the tweets list above \n",
    "                df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "                print(df)\n",
    "                SaveData(df, \"twitter_scraped_data\")\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a396247639a1e443f960a362f00bf550980e9f3165772b27b9b3d645262b2121"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
